%! TeX encoding = UTF-8
%! TeX program = LuaLaTeX

\documentclass[english, nochinese]{pnote}
\usepackage{siunitx}
\usepackage[paper, cgu]{pdef}
\usepackage{pgf}
\usepackage{biblatex}

\DeclareMathOperator\opvar{\mathrm{Var}}

\addbibresource{Bibliography.bib}

\title{Report for Exercises 1}
\author{Zhihan Li, 1600010653}
\date{December 27, 2018}

\begin{document}

\maketitle

\textbf{Problem.} We implement a parallel program to calculate the area of the Mandelbrot set. The algorithm and numerical results are shown in the following sections.

\emph{All the numerical results shown in the following sections except Section \ref{Sec:Par} are carried out on personal machine. The numerical results in Section \ref{Sec:Par} are for final submission, run on the provided 8-core machine.}

\section{The Mandelbrot set}

The Mandelbrot set $\mathcal{M}$ is defined as the set of $ c \in \mathbb{C} $ such that $ f_c^{\sbr{n}} \rbr{0} $ remains bounded for all $n$. Here
\begin{equation}
f_c \rbr{z} = z^2 + c
\end{equation}
and $f_c^{\sbr{n}}$ stands for iterations of $f_c$.

Mathematically, one may prove that if $ \abs{z} > 2 $ and $ c \in \mathcal{M} $, then $ f_c^{\sbr{n}} \rbr{z} $ must diverge. Hence, we may define sets
\begin{equation}
M_k = \cbr{ c \in \mathbb{C} : \abs{ f_c^{\sbr{k}} \rbr{0} } \le 2 }.
\end{equation}
Hence,
\begin{equation}
\mathcal{M} = \bigcap_k M_k
\end{equation}
is a compact set and its measure $ m \rbr{\mathcal{M}} $ is well-defined. In addition, $\mathcal{M}$ is connected.

Nevertheless, the exact area of $\mathcal{M}$ is still a challenging question. There are mainly two approaches to this problem: counting pixels, or approximating the area using series \parencite{ewing_area_1992}. Due to numerical issues such as rounding error, $ \pd \mathcal{M} $ will not be calculated, and hence the area estimated is $ m \rbr{\mathcal{M}^{\circ}} $. (Note that there lacks a solid proof about this.) Approximating series suffers from slow convergence, but it may converge to $ m \rbr{\mathcal{M}} $. It is still a open problem whether $ \pd \mathcal{M} $ has non-zero Lebesgue measure, and the discrepancy between results yielded by these two methods indicates a positive answer.

We utilize the pixel counting method in order to approximate $ A = m \rbr{\mathcal{M}^{\circ}} $. We use $ A_{\text{std}} = 1.5065918849 $ as the standard value for comparison according to the best approximation $ 1.5065918849 \pm 0.0000000048 $ now.

\section{Monte Carlo Algorithm}

We utilize Monte Carlo algorithm here. \emph{It should be noticed that since the boundary of $\mathcal{M}$ is highly irregular, and again the indicator function $I_{\mathcal{M}}$ has no continuity, we cannot expect deterministic algorithm to provide a answer with error estimation. One can always find magic numbers with a small error to the fixed value $A_{\text{std}}$, but it is impossible to find such numbers if high precision values of $A_{\text{std}}$ is complete unknown.}

Our algorithm falls into the framework of stratified Monte Carlo: we divided the region to be investigated into grids, and randomly uniformly samples points, one per grid. We then calculate the number of points lying in $M_k$ for a large $k$, and make an estimation of $ m \rbr{\mathcal{M}^{\circ}} $ according to standard Monte Carlo techniques. Since we sample points in each grid instead of sampling directly from the whole region, the algorithm corresponds stratified Monte Carlo method.

It is an interesting question how the variance is reduced, and what is the difference between this algorithm and direct Monte Carlo. Assume the search region has area $A_0$ and there are $N$ grids. And we also assume the area of $\mathcal{M}^{\circ}$ inside each grid to be $A_i$ for $ 1 \le i \le N $. As a result, the variance of such estimation is
\begin{equation}
\opvar \hat{A}_{\text{str}} = \rbr{\frac{A_0}{N}}^2 \sum_i \frac{ A_i N }{A_0} \rbr{ 1 - \frac{ A_i N }{A_0 } },
\end{equation}
while
\begin{equation}
\opvar \hat{A}_{\text{dir}} = A_0^2 \frac{A}{A_0} \rbr{ 1 - \frac{A}{A_0} }
\end{equation}
Since
\begin{equation}
\sum_i A_i = A,
\end{equation}
we immediately have
\begin{equation}
\opvar \hat{A}_{\text{str}} \le \opvar \hat{A}_{\text{dir}}
\end{equation}
from the concavity of $ f \rbr{x} = x \rbr{ 1 - x } $. This means the stratified Monte Carlo is always better than direct Monte Carlo, and therefore it has half-order convergence. Moreover, for the case of $\mathcal{M}^{\circ}$, the bound will never be tight since there are many $i$ such that $ A_i = 0 $ or $ A_i = A / N $, according to the connectivity of $\mathcal{M}$. Although we cannot derive the exact bound, $ \opvar \hat{A}_{\text{str}} $ should be smaller than $ \opvar \hat{A}_{\text{dir}} $ by a multiplication of a constant.

\section{Implementation}

\subsection{Cardioid and bulb checking}

The main complexity lies in $\mathcal{M}^{\circ}$, since points not lying in $M_k$ will finally escape in the first $k$ steps. As a result, we can perform fast checking on part of $\mathcal{M}^{\circ}$, according to its geometric properties.

The main cardioid can written analytically and we utilize
\begin{equation}
x \le p - 2 p^2 + \frac{1}{4}
\end{equation}
with
\begin{equation}
p = \sqrt{ \rbr{ x - \frac{1}{4} }^2 + y^2 }
\end{equation}
to perform fast checking of the cardioid.

There are also hyperbolic components (bulbs) tangent to the cardioid which can be checked. We use
\begin{equation}
\rbr{ x + 1 }^2 + y^2 \le \frac{1}{16}
\end{equation}
for the 1-bulb. We also perform fast checking of 2-bulbs and 3-bulbs according to \parencite{linas_vepstas_mandelbrot_nodate}. To be precise, for co-prime $p$ and $q$ there is a $q$-bulb with index $ p / q $ tangent to the cardioid at
\begin{equation}
z_{ p / q } = \frac{\se^{ \si t }}{2} - \frac{\se^{ 2 \si t }}{4}
\end{equation}
with
\begin{equation}
t = 2 \spi \frac{p}{q}.
\end{equation}
The radius is approximately (note that they are not exactly circles)
\begin{equation}
r_{ p / q } = \frac{ \sin \spi p / q }{q^2}
\end{equation}
and we calculate the inscribed circles by find the circle tangent to the cardioid at $ a_{ p / q } $ with radius $ \eta_{ p / q } r_{ p / q } $ where $ \eta_{ p / q } $ is a prescribed constant close to 1 selected according to \parencite{linas_vepstas_mandelbrot_nodate}.

\subsection{Selection of parameters}

The search region is set to be $ \Omega \sbr{ -2, 1 } \times \sbr{ 0, 3 / 2 } $. We only calculate the region of half of $\mathcal{M}^{\circ}$, because the other half is identical due to symmetry.

We set a fixed number $n$, decompose the region $\Omega$ into $ N = 2 n \times n $ grids. We also choose a number $L$ and estimate $A$ by estimating $ m \rbr{M_L} $. We test 10 times for each configuration and plot the mean error and standard deviation curve is plotted in Figure \ref{Fig:Err}. The numerical results are produced on personal machine with 4 cores.

\begin{figure}[htbp]
{
\centering
\input{Figure1.pgf}
\caption{Error and standard deviation of stratified Monte Carlo}
\label{Fig:Err}
}
{
\footnotesize Lines: mean error of 10 trials; dashed lines: standard deviation of 10 trials. We take the absolute value of mean error to plot in logarithm scale.
}
\end{figure}

From these figure, we may directly find the half-order convergence of variance, but we should also notice that there are bias when using $ m \rbr{M_L} $ to approximate $A$. According to the figure, if we want to achieve an accuracy about $10^{-5}$, we must control the bias under about $10^{-5}$ and hence $L$ should value at least 131072. From this figure, we know that $n$ should be set to about 4096 to 8192 for a reasonable variance, say standard deviation about $10^{-5}$.

The average running times of 10 trials are plotted in Figure \ref{Fig:Time}.

\begin{figure}[htbp]
\centering
\input{Figure2.pgf}
\caption{Running time of stratified Monte Carlo}
\label{Fig:Time}
\end{figure}

Rough but direct estimation yields the time complexity $ O \rbr{ L N } = O \rbr{ L n^2 } $. This figure verifies the algorithm.

\section{Multi-level Monte Carlo}

We then investigate the possibility using Multi-level Monte Carlo. To do this, we utilize stratified Monte Carlo to estimate $ m \rbr{ M_{ L / 2 } \setminus M_L } $. We also conduct 10 trials and the standard deviation is summarized in Figure \ref{Fig:Multi}.

\begin{figure}[htbp]
\centering
\input{Figure3.pgf}
\caption{Standard deviation of estimation of $ m \rbr{ M_{ L / 2 } \setminus M_L } $}
\label{Fig:Multi}
\end{figure}

From this figure, we verifies that for a fixed $n$, the estimation of $ m \rbr{ M_{ L / 2 } \setminus M_L } $ has smaller variance when $L$ increases. This indicates the possibility of multi-level Monte Carlo, since for smaller $L$ we may use larger $n$ to reduce variance, while for larger $L$ we may use smaller $n$ to increase efficiency.

Combining $ O \rbr{ L n^2 } $ time complexity and some experimental result (e.g. cache issues, scheduling cost and fast checking may get involved, and therefore we follow experiments instead of using analysis to do optimization), we use the following multi-level scheme:
\begin{partlist}
\item Estimate $ A_1 = -m \rbr{ M_{L_2} \setminus M_{L_1} } $ and grid $ N_1 = 2 n \times n $;
\item Estimate $ A_2 = -m \rbr{ M_{L_3} \setminus M_{L_2} } $ and grid $ N_2 = 4 n \times 2 n $;
\item Estimate $ A_3 = m \rbr{M_{L_3}} $ and grid $ N_3 = 8 n \times 4 n $,
\end{partlist}
with
\begin{equation}
L_1 = 4 L_2 = 16 L_3.
\end{equation}
The final estimation of $A$ is
\begin{equation}
\hat{A}_{\text{mul}} = \hat{A}_1 + \hat{A}_2 + \hat{A}_3.
\end{equation}

The comparison between direct stratified Monte Carlo and multi-level Monte Carlo is summarized in Table \ref{Tbl:Multi}. We again conduct 10 trials. Here we set $ L = L_1 = 131072 $.

\begin{table}[htbp]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Algorithm & $n$ & Mean error & Standard deviation & Time (\Si{s}) \\
\hline
\input{Table1.tbl}
\end{tabular}
\caption{Comparison between stratified Monte Carlo and multi-level Monte Carlo}
\label{Tbl:Multi}
\end{table}

From this result, we can see the multi-level Monte Carlo method with $ n = 1024 $ outperforms direct stratified Monte Carlo with $ n = 2048 $ both in accuracy, variance and speed. So for 2048 to 4096.

\section{Parallel algorithm} \label{Sec:Par}

We utilize OpenMP to run the algorithm on parallel with cores. Previous numerical algorithms are carried out on personal machine with 4 cores. The numerical results below is run on the provided machine with 8 cores. We use a single \verb"omp parallel for" for the first dimension of grids $ N = 2 n \times n $. Since there are only $ 2 n $ iterations for the first dimension and $n$ is not very large, we directly adopt dynamic scheduling. the numerical result is summarized in Table \ref{Tbl:Math}. The job ID is 4464.

\begin{table}[htbp]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Algorithm & $n$ & Mean error & Standard deviation & Time (\Si{s}) & Pass \\
\hline
Multi-level & 1024 & 2.21922e-5 & 2.01381e-5 & 6.22934 & 9 / 10 \\
\hline
Multi-level & 2048 & 2.62222e-5 & 9.47315e-6 & 24.79697 & 10 / 10 \\
\hline
\end{tabular}
\caption{Numerical result on 8 cores}
\label{Tbl:Math}
\end{table}

Using multi-level Monte Carlo with $ n = 1024 $ (and $ L_1 = 131072 $), we can roughly achieve $ 5 \times 10^{-5} $ error bound with reasonable probability since $ \mu + \sigma $ lies in the error bound and we have a probability of 83\% to pass the error bound restriction. This means 50\% of trials pass the restriction of bound. If we need a more stable result, we can set $ n = 2048 $ and here $ \mu + 3 \sigma $ approximately lies in the error bound, with a probability 99\%.

\printbibliography

\end{document}
